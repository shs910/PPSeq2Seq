log out:  False
gen both : True
batch_inference:  True
save results: True
loss use mean : False
cuda_device_id: 4
hetpandya/t5-base-tapaco
T5 base
vocab_size:  32128
vocab_size is unequal
model.config.vocab_size:  32128
tokenizer.vocab_size:  32100
classifier loaded!!
max_input_length: 512
eos_token_id:  1
pad_token_id:  0
begin......
laoding data....
total_num:1000,bath_szie:40,num_bath:25
  0%|          | 0/25 [00:00<?, ?it/s]/home/hssun/anaconda3/envs/torch_shs/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:190: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.
  warnings.warn(
  4%|▍         | 1/25 [04:11<1:40:29, 251.24s/it]  8%|▊         | 2/25 [07:59<1:31:05, 237.62s/it] 12%|█▏        | 3/25 [11:38<1:24:01, 229.15s/it] 16%|█▌        | 4/25 [15:38<1:21:46, 233.62s/it] 20%|██        | 5/25 [19:47<1:19:43, 239.20s/it] 24%|██▍       | 6/25 [24:00<1:17:12, 243.81s/it] 28%|██▊       | 7/25 [27:39<1:10:40, 235.60s/it] 32%|███▏      | 8/25 [32:34<1:12:09, 254.69s/it] 36%|███▌      | 9/25 [36:48<1:07:48, 254.29s/it] 40%|████      | 10/25 [41:07<1:03:57, 255.86s/it] 44%|████▍     | 11/25 [44:52<57:30, 246.48s/it]   48%|████▊     | 12/25 [48:25<51:10, 236.16s/it] 52%|█████▏    | 13/25 [52:26<47:33, 237.76s/it] 56%|█████▌    | 14/25 [56:22<43:26, 236.99s/it] 60%|██████    | 15/25 [59:41<37:37, 225.72s/it] 64%|██████▍   | 16/25 [1:03:49<34:51, 232.35s/it] 68%|██████▊   | 17/25 [1:07:33<30:38, 229.84s/it] 72%|███████▏  | 18/25 [1:11:11<26:24, 226.38s/it] 76%|███████▌  | 19/25 [1:15:12<23:04, 230.81s/it] 80%|████████  | 20/25 [1:19:00<19:09, 229.89s/it] 84%|████████▍ | 21/25 [1:23:06<15:38, 234.61s/it] 88%|████████▊ | 22/25 [1:26:41<11:26, 228.88s/it] 92%|█████████▏| 23/25 [1:30:29<07:37, 228.66s/it] 96%|█████████▌| 24/25 [1:33:41<03:37, 217.42s/it]100%|██████████| 25/25 [1:37:12<00:00, 215.68s/it]100%|██████████| 25/25 [1:37:12<00:00, 233.31s/it]

log out:  False
gen both : True
batch_inference:  True
save results: True
loss use mean : False
cuda_device_id: 4
hetpandya/t5-base-tapaco
T5 base
vocab_size:  32128
classifier loaded!!
max_input_length: 512
eos_token_id:  1
pad_token_id:  0
begin......
laoding data....
total_num:1000,bath_szie:50,num_bath:20
  0%|          | 0/20 [00:00<?, ?it/s]/home/hssun/anaconda3/envs/torch_shs/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:190: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.
  warnings.warn(
  5%|▌         | 1/20 [12:26<3:56:19, 746.32s/it] 10%|█         | 2/20 [24:41<3:42:00, 740.01s/it] 15%|█▌        | 3/20 [37:07<3:30:26, 742.74s/it] 20%|██        | 4/20 [49:23<3:17:20, 740.05s/it] 25%|██▌       | 5/20 [1:01:43<3:04:56, 739.76s/it] 30%|███       | 6/20 [1:14:04<2:52:43, 740.26s/it] 35%|███▌      | 7/20 [1:26:32<2:40:56, 742.81s/it] 40%|████      | 8/20 [1:38:45<2:27:56, 739.70s/it] 45%|████▌     | 9/20 [1:51:03<2:15:29, 739.08s/it] 50%|█████     | 10/20 [2:03:19<2:03:03, 738.33s/it] 55%|█████▌    | 11/20 [2:15:31<1:50:27, 736.41s/it] 60%|██████    | 12/20 [2:27:42<1:37:58, 734.78s/it] 65%|██████▌   | 13/20 [2:39:55<1:25:39, 734.17s/it] 70%|███████   | 14/20 [2:52:03<1:13:13, 732.33s/it] 75%|███████▌  | 15/20 [3:04:15<1:01:01, 732.23s/it] 80%|████████  | 16/20 [3:14:41<46:41, 700.30s/it]   85%|████████▌ | 17/20 [3:26:50<35:26, 708.96s/it] 90%|█████████ | 18/20 [3:38:57<23:48, 714.27s/it] 95%|█████████▌| 19/20 [3:51:03<11:57, 717.86s/it]100%|██████████| 20/20 [4:03:16<00:00, 722.32s/it]100%|██████████| 20/20 [4:03:16<00:00, 729.83s/it]

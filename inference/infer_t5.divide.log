log out:  False
gen both : True
batch_inference:  True
save results: True
loss use mean : False
cuda_device_id: 1
hetpandya/t5-base-tapaco
T5 base
vocab_size:  32128
classifier loaded!!
max_input_length: 512
eos_token_id:  1
pad_token_id:  0
begin......
laoding data....
total_num:1000,bath_szie:50,num_bath:20
  0%|          | 0/20 [00:00<?, ?it/s]/home/hssun/anaconda3/envs/torch_shs/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:190: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.
  warnings.warn(
  5%|▌         | 1/20 [12:28<3:56:57, 748.29s/it] 10%|█         | 2/20 [24:50<3:43:21, 744.55s/it] 15%|█▌        | 3/20 [37:00<3:29:02, 737.82s/it] 20%|██        | 4/20 [49:37<3:18:48, 745.52s/it] 25%|██▌       | 5/20 [1:01:23<3:02:52, 731.50s/it] 30%|███       | 6/20 [1:14:07<2:53:14, 742.45s/it] 35%|███▌      | 7/20 [1:26:34<2:41:12, 744.00s/it] 40%|████      | 8/20 [1:38:27<2:26:47, 733.98s/it] 45%|████▌     | 9/20 [1:50:52<2:15:12, 737.46s/it] 50%|█████     | 10/20 [2:02:53<2:02:02, 732.22s/it] 55%|█████▌    | 11/20 [2:14:37<1:48:34, 723.88s/it] 60%|██████    | 12/20 [2:27:41<1:38:55, 741.93s/it] 65%|██████▌   | 13/20 [2:39:41<1:25:48, 735.45s/it] 70%|███████   | 14/20 [2:51:57<1:13:33, 735.62s/it] 75%|███████▌  | 15/20 [3:03:53<1:00:48, 729.76s/it] 80%|████████  | 16/20 [3:15:57<48:31, 727.78s/it]   85%|████████▌ | 17/20 [3:27:59<36:18, 726.10s/it] 90%|█████████ | 18/20 [3:39:40<23:57, 718.65s/it] 95%|█████████▌| 19/20 [3:52:09<12:07, 727.59s/it]100%|██████████| 20/20 [4:04:02<00:00, 723.27s/it]100%|██████████| 20/20 [4:04:02<00:00, 732.11s/it]

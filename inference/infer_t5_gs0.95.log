log out:  False
gen both : True
batch_inference:  True
save results: True
loss use mean : False
cuda_device_id: 4
hetpandya/t5-base-tapaco
T5 base
vocab_size:  32128
vocab_size is unequal
model.config.vocab_size:  32128
tokenizer.vocab_size:  32100
classifier loaded!!
max_input_length: 512
eos_token_id:  1
pad_token_id:  0
begin......
laoding data....
total_num:1000,bath_szie:40,num_bath:25
  0%|          | 0/25 [00:00<?, ?it/s]/home/hssun/anaconda3/envs/torch_shs/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:190: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.
  warnings.warn(
  4%|▍         | 1/25 [03:23<1:21:16, 203.20s/it]  8%|▊         | 2/25 [06:42<1:17:05, 201.13s/it] 12%|█▏        | 3/25 [09:52<1:11:50, 195.94s/it] 16%|█▌        | 4/25 [12:28<1:02:58, 179.93s/it] 20%|██        | 5/25 [16:18<1:06:04, 198.24s/it] 24%|██▍       | 6/25 [19:32<1:02:20, 196.88s/it] 28%|██▊       | 7/25 [22:55<59:39, 198.85s/it]   32%|███▏      | 8/25 [26:45<59:07, 208.69s/it] 36%|███▌      | 9/25 [30:02<54:42, 205.14s/it] 40%|████      | 10/25 [34:07<54:19, 217.31s/it] 44%|████▍     | 11/25 [37:05<47:51, 205.13s/it] 48%|████▊     | 12/25 [40:09<43:05, 198.90s/it] 52%|█████▏    | 13/25 [43:19<39:13, 196.12s/it] 56%|█████▌    | 14/25 [46:44<36:28, 198.98s/it] 60%|██████    | 15/25 [49:59<32:56, 197.62s/it] 64%|██████▍   | 16/25 [53:11<29:23, 195.94s/it] 68%|██████▊   | 17/25 [56:15<25:37, 192.24s/it] 72%|███████▏  | 18/25 [59:42<22:56, 196.71s/it] 76%|███████▌  | 19/25 [1:02:42<19:11, 191.91s/it] 80%|████████  | 20/25 [1:05:04<14:43, 176.80s/it] 84%|████████▍ | 21/25 [1:08:00<11:46, 176.59s/it] 88%|████████▊ | 22/25 [1:11:13<09:04, 181.35s/it] 92%|█████████▏| 23/25 [1:14:23<06:08, 184.03s/it] 96%|█████████▌| 24/25 [1:17:01<02:56, 176.32s/it]100%|██████████| 25/25 [1:20:20<00:00, 182.96s/it]100%|██████████| 25/25 [1:20:20<00:00, 192.81s/it]
